---
discussionID: u4inYI5U8z1-ZqGZ2QPKh
---
# 音视频

- 音视频
  - 流媒体协议
    - RTP/RTCP
    - SRTP/SRTCP
    - RTMP/RTMPS
    - HLS (HTTP Live Streaming)：一种基于HTTP协议的流媒体传输协议
  - 媒体设备
    - 音频设备
      - 采样率
      - 采样大小
    - 视频设备
      - 通过光学传感器将光转换成数字信号，即 RGB（Red、Green、Blue）数据（每一种颜色由 8 位组成，所以一个像素就需要用 24 位表示）
      - 从摄像头里采集的帧或通过解码器解码后的帧都是非编码帧。非编码帧的格式一般是 YUV 格式或是 RGB 格式
      - 图像数据还要进行压缩、传输，而编码器一般使用的输入格式为 YUV I420，所以在摄像头内部还有一个专门的模块用于将 RGB 图像转为 YUV 格式的图像
      - 通过编码器（如 H264/H265、VP8/VP9）压缩后的帧称为编码帧
        - 经过 H264 编码的帧包括以下三种类型
          - I  帧：关键帧。压缩率低，可以单独解码成一幅完整的图像
          - P 帧：参考帧。压缩率较高，解码时依赖于前面已解码的数据
          - B 帧：前后参考帧。压缩率最高，解码时不光依赖前面已经解码的帧，而且还依赖它后面的 P 帧。换句话说就是，B 帧后面的 P 帧要优先于它进行解码，然后才能将 B 帧解码
  - WebAPI
    - HTMLVideoElement
    - [MediaDevices](https://developer.mozilla.org/zh-CN/docs/Web/API/MediaDevices)
      - `navigator.mediaDevices`
        - [getUserMedia](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)
        - [getDisplayMedia](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getDisplayMedia)
        - 安全源限制
          - HTTPS
          - 回路地址：localhost、127.0.0.1、::1
          - `file://` 文件协议
    - [MediaStream](https://developer.mozilla.org/en-US/docs/Web/API/Media_Capture_and_Streams_API)
      - 一个媒体流包含多个轨
      - [MediaStreamTrack](https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamTrack)
        - “轨”在多媒体中表达的就是每条轨数据都是独立的，不会与其他轨相交
        - MediaTrackConstraints  ![图 1](./images/1669797968450.png) 
    - MediaRecorder：媒体录制
    - WebRTC
      - [SDP](#sdp)
      - [WebRTC 建立连接](#webrtc-建立连接)

## SDP

- SDP（Session Description Protocal）：用文本描述的各端支持的音频编解码器以及参数、传输协议、音视频媒体等
- SDP 是一个文本描述格式，其结构是由多个 `<type>=<value>` 组成，“=” 两边是不能有空格的 
- SDP = 一个会话级描述（session level description）+ 多个媒体级描述（media level description）组成
  - 会话级从 v= 行开始到第一个媒体描述 m 为止
  - 媒体级从 m= 行开始到下一个媒体描述（即下一个 m=）为止
  - 媒体级描述：`m=<媒体类型> <端口> <传输协议> <媒体格式>`
  - 属性描述：用于进一步描述媒体信息
  ```
    v=0
    o=- 7017624586836067756 2 IN IP4 127.0.0.1
    s=-
    t=0 0
    //下面 m= 开头的两行，是两个媒体流：一个音频，一个视频。
    m=audio 9 UDP/TLS/RTP/SAVPF 111 103 104 9 0 8 106 105 13 126
    a=rtpmap:111 opus/48000/2
    ...
    m=video 9 UDP/TLS/RTP/SAVPF 96 97 98 99 100 101 102 122 127 121 125 107 108 109 124 120 123 119 114 115 116
    ...
    ```
- WebRTC 中的 SDP

## WebRTC 建立连接

- WebRTC 建立连接
  - 原理
    - 媒体协商：交换 SDP，了解对方媒体能力，找到共同支持的媒体能力
      - 通信双方将它们各自的媒体信息能力按 **SDP** 格式整理好
      - 通过**信令服务**器交换 SDP 信息，并待彼此拿到对方的 SDP 信息后，找出它们共同支持的媒体能力
      - 最后双方进行媒体协商，才能按照协商好的媒体能力开始音视频通信
    - ICE（Interactive Connectivity Establishment）：收集各种类型 ICE Candidate，寻找最佳连接方案
      - Candidate 类型及收集
        - host 类型：即本机内网的 IP 和端口
        - srflx 类型：即本机 NAT 映射后的外网的 IP 和端口，通过 **STUN** 协议收集 srflx 类型的 Candidate
          - prflx 类型：与 srflx 一样，但 srflx 是通过 STUN 服务获取的，而prflx 则是直接向目的主机发起请求
        - relay 类型：即中继服务器的 IP 和端口，通过 **TURN** 协议收集 relay 类型的 Candidate
      - WebRTC 按优先级顺序对 Candidate 进行连通性检测
        - 首先对 host 类型的候选者进行**内网之间的连通性检测**，判断两台主机是否处于同一个局域网内
        - 其次尝试 srflx 类型的候选者，也就是尝试让通信双方直接通过 P2P 进行连接
          - WebRTC 首先需要对 NAT 类型做判断，检测出其类型后，才能判断出是否可以打洞成功，只有存在打洞成功的可能性时才会真正尝试打洞
          - 对称型 NAT 与对称型 NAT 是无法进行 P2P 穿越的；而对称型 NAT 与端口限制型 NAT 也是无法进行 P2P 连接的
        - 最后通过中继服务器进行中转
  - 调用 RTCPeerConnection 接口创建连接  ![图 1](./images/1672507499198.png)  
    - 通信双方链路的建立是在设置本地媒体能力，即调用 setLocalDescription 函数之后才进行的

## 实战

- 音视频录制
  - 录制端
    - 服务端录制
    - 客户端录制
      - 优点高清
      - 编码耗性能
  - 多媒体文件格式
    - 原始数据、自定义格式、可做私有播放
    - flv
      - 支持流式，可边录制边播放
      - 缺点，单视频模式
    - mp4
      - 多媒体格式
  - 录制行为
    - 边录边看
    - 录制完立即回放
    - 录完后过一段时间可观看
  - 录制多人互动场景
    - 录制桌面流 + 多路音频
  - TODO
    - 是否可以将多路音视频录制到同一个多媒体文件中呢？
    - 是否可以将这三个人的视频写入到一个多媒体文件中呢（如 MP4）？这样的 MP4 在播放时会有什么问题吗？
- 共享桌面
  - 原理
    - 抓屏
    - 压缩编码
    - 传输
    - 解码
    - 显示
    - 控制
    - 远程控制端
  - 协议
    - 内容 = 桌面数据 + 信令控制
    - 协议
      - RDP（Remote Desktop Protocal）协议
      - **VNC（Virtual Network Console）**
- 网络断开重连
- 音视频服务质量优化与提升
  - 传输速率控制
    - 带宽限制
  - 网络质量
    - 物理链路质量
      - 丢包
      - 延迟
      - 抖动：指的是数据传输一会儿快、一会儿慢，很不稳定。容易造成视觉抖动
        - 缓冲
    - 带宽大小
      - 带宽大小指的是每秒钟可以传输多少数据，单位 bps。
        - 比如 1M 带宽，它表达的是每秒钟可以传输 1M 个 bit 位
        - 换算成字节就是 1Mbps/8 = 128KBps
      - 准则：把带宽尽量占满，但千万别超出带宽的限制
    - 传输速率
  - 数据
    - 分辨率
    - 帧率
    - 音视频压缩码率：指的是单位时间内音视频被压缩后的数据大小
    - 传输控制码率
- 多对多实时通信
  - Mesh 方案，即多个终端之间两两进行连接，形成一个网状结构。



- 虽然出于隐私原因无法访问有关用户摄像头和麦克风的信息，但应用程序可以使用额外的约束来请求它需要和想要的摄像头和麦克风功能
- 性能调优
  - 分辨率\帧率\宽带 调参
  - 视频模糊
    - 宽带问题
    - 关闭 Web RTC 的自适应码率，frameRate，width，height 设置固定值或高范围值。














- 我曾就职于多家知名互联网企业，现在在硅谷某巨头 IT 企业担任资深软件工程师，主要负责 Maps 相关产品的研发工作，参与移动产品的设计、实现及开源软件的开发和维护。
- 我便将力扣（LeetCode）上的题目按公司、题目热门程度、以及难度进行排序后，制定学习计划，坚持做完了所有题目，如愿拿到了大厂 Offer


- RTCPeerConnection 细节
  - 端与端之间要建立连接，但它们是如何知道彼此的外网地址呢？
  - 如果两台主机都是在 NAT 之后，它们又是如何穿越 NAT 进行连接的呢？
  - 如果 NAT 穿越不成功，又该如何保证双方之间的连通性呢？
- adapter.js
- 在 WebRTC 端与端之间建立连接，包括三个任务：
为连接的每个端创建一个 RTCPeerConnection 对象，并且给 RTCPeerConnection 对象添加一个本地流，该流是从 getUserMedia() 获取的；
获取本地媒体描述信息，即 SDP 信息，并与对端进行交换；
获得网络信息，即 Candidate（IP 地址和端口），并与远端进行交换


- RTCDataChannel
  - WebRTC 的 RTCDataChannel 使用的传输协议为 SCTP，即 Stream Control Transport Protocol。

## 中继服务

- Stun Server
  - STUN 是一种允许主机应用程序发现网络上是否存在 NAT 的协议，如果找到，则获取当前连接的公共 IP 地址和端口
  - 要实现这一点，STUN 协议需要公共网络上众所周知的第三方服务器，即称为 STUN 服务器的互联网

## 实战

- 多对多
  - 架构
    - Mesh
    - SFU