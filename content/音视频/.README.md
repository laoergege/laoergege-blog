---
discussionID: u4inYI5U8z1-ZqGZ2QPKh
release: true
tags:
 - webrtc
 - 音视频
 - web
---
<<<<<<< HEAD

# WebRTC 与音视频
=======
# 音视频
>>>>>>> dev

- 音视频
  - Web Media API
    - https://developer.mozilla.org/en-US/docs/Web/Media
  - 概念
    - 摄像头
      - 参数
        - 分辨率
        - 前置或者后置摄像头
        - 帧率
  - 流媒体协议
    - HLS (HTTP Live Streaming)：基于 HTTP 协议的流媒体传输协议
    - WebRTC
      - WebRTC 协议
        - 信令（Signaling）
          - 媒体协商：客户端之间交换 SDP 信息，了解对方媒体能力，找到共同支持的媒体能力
            - 通信双方将它们各自的媒体信息能力按 **SDP** 格式整理好
            - 通过**信令服务**器交换 SDP 信息，并待彼此拿到对方的 SDP 信息后，找出它们共同支持的媒体能力
          - SDP(会话描述协议)
        - 连接（Connecting）
          - ICE(交互式连接建立)
            - NAT 穿透 - 使用 STUN/TURN 进行连接
        - 安全加密（Securing）
          - DTLS（数据报传输层安全性），即基于 UDP 的 TLS
        - 通信（Communicating）
          - 使用 SRTP（安全实时传输协议）传输的媒体数据
          - 使用 SCTP （流控制传输协议）和 DTLS 加密传输 DataChannel 消息
      - WebRTC API
        - https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API#webrtc_concepts_and_usage
        - [MediaDevices](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices)
          - 安全源限制
            - HTTPS
            - 回路地址：localhost、127.0.0.1、::1
            - `file://` 文件协议
          - [mediaDevices.getUserMedia](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)
          - [mediaDevices.getDisplayMedia](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getDisplayMedia)
        - [MediaStream](https://developer.mozilla.org/en-US/docs/Web/API/Media_Capture_and_Streams_API)
        - 一个媒体流包含多个轨
        - [MediaStreamTrack](https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamTrack)
          - “轨”在多媒体中表达的就是每条轨数据都是独立的，不会与其他轨相交
          - MediaTrackConstraints  ![图 1](./images/1669797968450.png) 
<<<<<<< HEAD
      - 媒体约束 constraints
        - video
          - 分辨率
          - 帧率
      - 获取用户层面的媒体：[`navigator.mediaDevices.getUserMedia`](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)
      - 屏幕分享：[`navigator.mediaDevices.getDisplayMedia`](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getDisplayMedia)
    - Peer
      - RTCRtpSender
      - createDataChannel
    - MediaRecorder：媒体录制
    - HTMLVideoElement
- [多对多架构](#多对多架构)
::

## WebRTC 会话

- 媒体协商
  - 客户端之间通过信令（Signaling）服务交换 SDP 信息，了解对方媒体能力，找到共同支持的媒体能力
    - 通信双方将它们各自的媒体信息能力按 **SDP** 格式整理好
    - 通过**信令服务**器交换 SDP 信息，并待彼此拿到对方的 SDP 信息后，找出它们共同支持的媒体能力
  - [SDP(会话描述协议)](#sdp会话描述协议)
  - ![](./images/1700641218465.png) 
- ICE(交互式连接建立)
  - NAT 穿透 - 使用 STUN/TURN 进行连接
- 安全加密（Securing）
  - DTLS（数据报传输层安全性），即基于 UDP 的 TLS
- 通信（Communicating）
  - 使用 SRTP（安全实时传输协议）传输的媒体数据
  - 使用 SCTP （流控制传输协议）和 DTLS 加密传输 DataChannel 消息
=======
      - MediaRecorder：媒体录制
      - HTMLVideoElement
>>>>>>> dev

## SDP(会话描述协议)

> [wiki-Session Description Protocol](https://en.wikipedia.org/wiki/Session_Description_Protocol)
> [SDP: Session Description Protocol](https://datatracker.ietf.org/doc/html/rfc4566#section-8)

- SDP（Session Description Protocal）：用文本描述的各端支持的音频编解码器以及参数、传输协议、音视频媒体等
  - 文本描述格式，其结构是由多个 `<type>=<value>/n` 组成，“=” 两边是不能有空格的 
  - SDP = 一个会话级描述（session level description）+ 多个媒体级描述（media level description）
  - 会话级
    - 从 `v=` 行开始到第一个媒体描述 m 为止
    - `v`：表示 SDP 的版本号
    - `o=<username> <session id> <version> <network type> <address type> <address>`
      - `<username>`：用户名，当不关心用户名时，可以用 “－” 代替 ；
      - `<session id>`：数字串，在整个会话中，必须是唯一的，建议使用 NTP 时间戳；
      - `<version>`：版本号，每次会话数据修改后，该版本值会递增；
      - `<network type>`：网络类型，一般为“IN”，表示“internet”
      - `<address type>`：地址类型，一般为 IP4；
      - `<address>`：IP 地址
    - `s=<session name>`
    - `t=<start time> <stop time>`：描述了会话的开始时间和结束时间
      - `t=0 0`：表示持久会话
  - 媒体级
    - 从 `m=` 行开始到下一个媒体描述（即下一个 `m=`）为止
    - 媒体级描述：`m=<媒体类型> <端口> <传输协议> <媒体格式>`
    - 属性描述：用于进一步描述媒体信息
      - 从 `a=` 开始，一整行
      - `a=<TYPE>:<VALUES>`
        - TYPE: rtpmap 或者 fmtp
        - rtpmap：rtp 与 map 的结合，即 RTP 参数映射
          - `a=rtpmap:<payload type> <encoding name>/<clock rate>[/<encodingparameters>]`
            - `<payload type>` ：负载类型，对应 RTP 包中的音视频数据负载类型
            - `<encoding name>`：编码器名称，如 VP8、VP9、OPUS 等
            - `<sample rate>`：采样率，如音频的采样率频率 32000、48000 等
            - `<encodingparameters>`：编码参数，如音频是否是双声道，默认为单声道
        - fmtp：格式化参数
          - `a=fmtp:<payload type> <format specific parameters>`
          - `<payload type>`，负载类型，同样对应 RTP 包中的音视频数据负载类型
          - `<format specific parameters>` 指具体参数
- 对于每个媒体层，WebRTC 把媒体级描述的内容分为了
  - 网络描述
  - 媒体流描述
  - 安全描述（新增属性）
  - 服务质量描述（新增属性）

## ICE(交互式连接建立)

::tl
- ICE（Interactive Connectivity Establishment）
  - 收集各类 Candidate 类型
    - host 类型：即本机内网的 IP 和端口
    - srflx 类型：即本机 NAT 映射后的外网的 IP 和端口，使用 **STUN** 协议收集 srflx 类型的 Candidate
      - prflx 类型：与 srflx 一样，但 srflx 是通过 STUN 服务器获取的，而prflx 则是直接向目的主机发起请求
    - relay 类型：即中继服务器的 IP 和端口，使用 **TURN** 协议收集 relay 类型的 Candidate
  - 对 Candidate 进行连通性检测
    - 首先对 host 类型的候选者进行**内网之间的连通性检测**，判断两台主机是否处于同一个局域网内
    - 其次尝试 srflx 类型的候选者，也就是尝试让通信双方直接通过 P2P 进行连接
      - WebRTC 首先需要对 NAT 类型做判断，检测出其类型后，才能判断出是否可以打洞成功，只有存在打洞成功的可能性时才会真正尝试打洞
      - 对称型 NAT 与对称型 NAT 是无法进行 P2P 穿越的；而对称型 NAT 与端口限制型 NAT 也是无法进行 P2P 连接的
    - 最后通过中继服务器进行中转
- 通信双方链路的建立是在设置本地媒体能力，即调用 setLocalDescription 函数之后才进行的
::

## 多对多架构

- Mesh 方案，即多个终端之间两两进行连接，形成一个网状结构
- MCU（Multipoint Conferencing Unit）方案
  - ![](./images/5f4646e3000e13c0ad86cfdc3307332b6ed1fa3e103bcfdcbd0011b95e32288d.png)  
  - 由一个服务器和多个终端组成一个星形结构
  - 由服务器混合各端的音视频流再发给各个终端
- SFU（Selective Forwarding Unit）
  - ![](./images/1700634380524.png)  
  - 由一个服务器和多个终端组成一个星形结构
  - SFU 不对音视频进行混流，只进行转发
  - 视频的处理模式
    - Simulcast 模式就是指视频的共享者可以同时向 SFU 发送多路不同分辨率的视频流；而 SFU 可以将接收到的三路流根据各终端的情况而选择其中某一路发送出去，这对于网络环境差的特别有用
      - ![图 2](./images/1700635383346.png)  
    - SVC 是可伸缩的视频编码模式：视频编码时将视频分成多层——核心层、中间层和扩展层。上层依赖于底层，而且越上层越清晰，越底层越模糊。在带宽不好的情况下，可以只传输底层，即核心层，在带宽充足的情况下，可以将三层全部传输过去
      - ![图 3](./images/1700635849346.png)  

## Q

<<<<<<< HEAD
- ice candidate 是什么时候发生
  - setLocalDescription 之后开始收集 candidate
  - sdp 如无媒体描述，是不会进行收集 candidate
  - ice-options:trickle 
  - onicecandidate 事件进行 candidate 交换
- 调试
  - chrome://webrtc-internals/
- 网络断开、重连
  - iceconnectionstatechange
  - restart
- 设备切换
=======











    - 视频设备
      - 通过光学传感器将光转换成数字信号，即 RGB（Red、Green、Blue）数据（每一种颜色由 8 位组成，所以一个像素就需要用 24 位表示）
      - 从摄像头里采集的帧或通过解码器解码后的帧都是非编码帧。非编码帧的格式一般是 YUV 格式或是 RGB 格式
      - 图像数据还要进行压缩、传输，而编码器一般使用的输入格式为 YUV I420，所以在摄像头内部还有一个专门的模块用于将 RGB 图像转为 YUV 格式的图像
      - 通过编码器（如 H264/H265、VP8/VP9）压缩后的帧称为编码帧
        - 经过 H264 编码的帧包括以下三种类型
          - I  帧：关键帧。压缩率低，可以单独解码成一幅完整的图像
          - P 帧：参考帧。压缩率较高，解码时依赖于前面已解码的数据
          - B 帧：前后参考帧。压缩率最高，解码时不光依赖前面已经解码的帧，而且还依赖它后面的 P 帧。换句话说就是，B 帧后面的 P 帧要优先于它进行解码，然后才能将 B 帧解码



## 实战

- 音视频录制
  - 录制端
    - 服务端录制
    - 客户端录制
      - 优点高清
      - 编码耗性能
  - 多媒体文件格式
    - 原始数据、自定义格式、可做私有播放
    - flv
      - 支持流式，可边录制边播放
      - 缺点，单视频模式
    - mp4
      - 多媒体格式
  - 录制行为
    - 边录边看
    - 录制完立即回放
    - 录完后过一段时间可观看
  - 录制多人互动场景
    - 录制桌面流 + 多路音频
  - TODO
    - 是否可以将多路音视频录制到同一个多媒体文件中呢？
    - 是否可以将这三个人的视频写入到一个多媒体文件中呢（如 MP4）？这样的 MP4 在播放时会有什么问题吗？
- 共享桌面
  - 原理
    - 抓屏
    - 压缩编码
    - 传输
    - 解码
    - 显示
    - 控制
    - 远程控制端
  - 协议
    - 内容 = 桌面数据 + 信令控制
    - 协议
      - RDP（Remote Desktop Protocal）协议
      - **VNC（Virtual Network Console）**
- 网络断开重连
>>>>>>> dev
- 音视频服务质量优化与提升
  - 传输速率控制
    - 带宽限制
  - 网络质量
    - 物理链路质量
      - 丢包
      - 延迟
      - 抖动：指的是数据传输一会儿快、一会儿慢，很不稳定。容易造成视觉抖动
        - 缓冲
    - 带宽大小
      - 带宽大小指的是每秒钟可以传输多少数据，单位 bps。
        - 比如 1M 带宽，它表达的是每秒钟可以传输 1M 个 bit 位
        - 换算成字节就是 1Mbps/8 = 128KBps
      - 准则：把带宽尽量占满，但千万别超出带宽的限制
    - 传输速率
  - 数据大小
    - 分辨率
    - 帧率
    - 音视频压缩码率：指的是单位时间内音视频被压缩后的数据大小
    - 传输控制码率
<<<<<<< HEAD
<<<<<<< HEAD
- outbound bandwidth 限制
=======
- 多对多实时通信
  - Mesh 方案，即多个终端之间两两进行连接，形成一个网状结构。



- 虽然出于隐私原因无法访问有关用户摄像头和麦克风的信息，但应用程序可以使用额外的约束来请求它需要和想要的摄像头和麦克风功能
- 性能调优
  - 分辨率\帧率\宽带 调参
  - 视频模糊
    - 宽带问题
    - 关闭 Web RTC 的自适应码率，frameRate，width，height 设置固定值或高范围值。














- 我曾就职于多家知名互联网企业，现在在硅谷某巨头 IT 企业担任资深软件工程师，主要负责 Maps 相关产品的研发工作，参与移动产品的设计、实现及开源软件的开发和维护。
- 我便将力扣（LeetCode）上的题目按公司、题目热门程度、以及难度进行排序后，制定学习计划，坚持做完了所有题目，如愿拿到了大厂 Offer


- RTCPeerConnection 细节
  - 端与端之间要建立连接，但它们是如何知道彼此的外网地址呢？
  - 如果两台主机都是在 NAT 之后，它们又是如何穿越 NAT 进行连接的呢？
  - 如果 NAT 穿越不成功，又该如何保证双方之间的连通性呢？
- adapter.js
- 在 WebRTC 端与端之间建立连接，包括三个任务：
为连接的每个端创建一个 RTCPeerConnection 对象，并且给 RTCPeerConnection 对象添加一个本地流，该流是从 getUserMedia() 获取的；
获取本地媒体描述信息，即 SDP 信息，并与对端进行交换；
获得网络信息，即 Candidate（IP 地址和端口），并与远端进行交换


- RTCDataChannel
  - WebRTC 的 RTCDataChannel 使用的传输协议为 SCTP，即 Stream Control Transport Protocol。

## 中继服务

- Stun Server
  - STUN 是一种允许主机应用程序发现网络上是否存在 NAT 的协议，如果找到，则获取当前连接的公共 IP 地址和端口
  - 要实现这一点，STUN 协议需要公共网络上众所周知的第三方服务器，即称为 STUN 服务器的互联网

## 实战

- 多对多
  - 架构
    - Mesh
    - SFU


- TCP
  - 可靠性
    - 发送 -> 确认；超时 -> 重发
- 网络问题
  - 丢包
  - 乱序
  - 延迟
- 协议设计
  - 序号：用于标识传输包的序号，这样就可以知道这个包是第几个分片了。
  - 起始标记：记录分帧的第一个 UDP 包。
<<<<<<< HEAD
  - 结束标记：记录分帧的最后一个 UDP 包
>>>>>>> cd734369 (fix)
=======
- outbound bandwidth 限制
>>>>>>> e12846f6 (fix)
=======
  - 结束标记：记录分帧的最后一个 UDP 包
>>>>>>> dev
